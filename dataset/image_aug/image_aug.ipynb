{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True)\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "totensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1715313196182251"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(totensor(trainset[1][0]).shape)\n",
    "torch.min(totensor(trainset[1][0]))\n",
    "loss(totensor(trainset[1][0]), totensor(trainset[2][0])).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADjklEQVR4nAXByW8bVRwA4Pfe/N7MeDwe7+N4yeK4JmnSKEAFSgMCJA4UIU5w4Y/gz+IEJ1QEEgeEKqRIFKqKRGlqksZOMo2D1xl7trfxffj7Xl+ubtbMk39DVTAO3/KPZXoyS9kk5NWi4DHMiiGsShnPU3et3XT1YovHsxElZcs3JPVTEEnUXaYlvXtQL6AMFmFqFTunKMzTuZLTSEEi9HFtp0kFu+6p470D5Q90w+2bSx+cSHADQqv4djs9X/iTYR7/gD6gK2j2HHIiJVU+JlAAg+jj/sTTNBbV3mT8ixXabHn/1K4ES22aOAD2tH8C6RLH/mJgdfnTja2ykRNxNOdm4LA0hOJgQANf+Uvdtdu5Y8xHe/cah6epKeWtUUQR9M5uQufe7n/DWrs08QeT3a2FZH9uNY+GLJ5l5RKelrfV/S4DpVOx4GJoOx0UPE8/2YvPrQLyE/AeZIyV2aXEmmSpcARVSFktqnYL8a2rqE9sPOUszuctSCTGJSsDSmqmlXj2F+/ZIB2ySuJpmOBYEJIrmQxliBRAFgrG9NG6CELAbGH6SUCy5WLZnK1zxqXSioI7WpDez/10B0JlSt0MCUJre13zG5f5IiBiJUhTpXDufvkEDrdvGl0XBSm2bYoWDzoCcUxjrlEthbT8IezvR44i4GIsGU86ZogxUkpFQsOzy0NmgmVZmsJYcUUUQnkhESKSKKGQUvPrTYA8iVSyYAlnLFzKgpM3BMK5SSSRsNdCmYMftekcJUNZKcP8VbABTrvVtjJ5jQO0bEFL+HFDHLUq52K3NjzEMfR7o/zX+xcYZTHSOcEIvikHJ3WS4Tuu+7kdIcnu+pZ3ym4+Xhc6SEVAfzlTbIGNaHT1ix84BfumWvj1gt3MtpyClTWyMHni8ReYo5/pOxAPxon3+t1vjxaRePYXpXp27StYaStCNGlC47Ns9rjXlMbLs6a3qmeH3ojJ2acwOvhIByIxSzw2Ph9WKBW/dRww4nlOTsrsd7DmL6oumzK1VrlY1ApG2PDGTcUMkSEj3EwU0PgPluUR3ni4+WZkNkY7u9+RKBVCb1+T7HZUhxA/ZkISsCbzQO+NNjuJISINcby5yD0bLCPIilKiaXomCfR1eoFNr1yJ4mWUGHXvanlaFjAX2t0ZzVWrpCDDav321UYShH7I9OPErVerJjAljKMhvP9o/nf8+jJUOX/mYy1Xq9Qf5kHD6n/dT/2M6MAzYQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32 at 0x7F8505182978>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grayconvert = torchvision.transforms.Grayscale(num_output_channels=1)  \n",
    "print(totensor(grayconvert(trainset[1][0])).shape)\n",
    "grayconvert(trainset[1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9922)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.max(totensor(grayconvert(trainset[1][0]))))\n",
    "torch.min(totensor(grayconvert(trainset[1][0])))\n",
    "totensor(grayconvert(trainset[1][0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17110250890254974"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(totensor(grayconvert(trainset[1][0])), totensor(grayconvert(trainset[2][0]))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
